{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Supervised Learning CC2 Solution.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/schwaaweb/aimlds1_07-TheMachineLearningFramework/blob/master/Th07_CCS--DJ--Deploying_A_Trained_Model__Supervised_Learning_CC2_Solution.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "pTf0zGED8g5P",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Deploying a Trained Model\n",
        "\n",
        "Once you have trained and optimized a machine learning model to your satisfaction (or your boss's), it is important to be able to take the trained model and deploy it in a way that will allow it to actually be *used* by stakeholders. This will most likely be on a website or through some other application, but mostly likely you wont want to have everyone coming back to your iPython notebook everytime that they want to make a prediction on new data. \n",
        "\n",
        "When deploying a model it needs to be deployed in an environment that is using the same version of python and the libraries that were use to originally train it, but what is more important is that we preserve the model's parameterization. A model's parameters and hyperparameters are what we've truly been after this whole time. If we could extract a model's parameterization and move those parameters to a similar deployment environment --regardless of whether that is on a website, phone app, or other hardware-- we would be able to make predictions just like usual. Then **if** (a big *if* here) the new data that your model sees in this new enviroment was represented well by the training data, it might even give good predictions.\n",
        "___\n",
        "\n",
        "Today's code challenge is all about getting your model's parameterization out of your iPython notebook in a way that will preserve it and allow the model to be redeployed at a later date."
      ]
    },
    {
      "metadata": {
        "id": "EZW1VcAnwWah",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# LAMBDA SCHOOL\n",
        "# \n",
        "# MACHINE LEARNING\n",
        "#\n",
        "# MIT LICENSE\n",
        "\n",
        "#Code to make your life a little easier\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.externals import joblib\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\"\n",
        "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
        "df = pd.read_csv(url, names=names)\n",
        "\n",
        "Y = df['class']\n",
        "X = df.drop(['class'], axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "T7viNtVNDLk5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## The Code Challenge:\n",
        "\n",
        "Your challenge for today, is to:\n",
        "\n",
        "1) Train a logistic regression classifier on the Pima Indians diabetes dataset. Do this using a C value of 20 and a penalty of \"l1\" for your hyperparameters. We'll pretend that we have already done hyperparameter tuning on this model previously for time's sake. \n",
        "\n",
        "2) use sklearn.externals.joblib in order to save a serialized version of your fitted model (which will contain the all-important model parameterization) to your machine\n",
        "\n",
        "3) Upload the saved model from your machine and use it to make predictions on some \"new\" data. I have generated some new (albeit fake) data which lives in this github repository: \n",
        "\n",
        "[https://raw.githubusercontent.com/ryanleeallred/fake-data/master/fake-data.csv](https://raw.githubusercontent.com/ryanleeallred/fake-data/master/fake-data.csv)\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "vVbBfYMJCvxQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Train Logistic Regression"
      ]
    },
    {
      "metadata": {
        "id": "j0kH3MNNFItd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c5f71a60-082f-465f-f95f-2023a224f5cc"
      },
      "cell_type": "code",
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=.2, random_state=12)\n",
        "model = LogisticRegression(C=20, penalty=\"l1\")\n",
        "model.fit(X_train, Y_train)\n",
        "result = model.score(X_test, Y_test)\n",
        "print(\"Accuracy: %.3f%%\" % (result*100.0))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 81.169%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "U6dYJoEHC0lt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Save the model to \"disk\" (colab/google drive in our case)"
      ]
    },
    {
      "metadata": {
        "id": "XB0zpdN3yMGN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7dea275e-07bc-4eec-c6fe-b8982969df49"
      },
      "cell_type": "code",
      "source": [
        "filename = 'finalized_model.sav'\n",
        "joblib.dump(model, filename) "
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['finalized_model.sav']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "metadata": {
        "id": "hEglmPoYDK4R",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Load model from \"disk\" and score it to prove that it's working."
      ]
    },
    {
      "metadata": {
        "id": "V4v1iBE9Cusi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "448dc1ec-20d3-46d2-bd03-5ae944b5bdd3"
      },
      "cell_type": "code",
      "source": [
        "# Do this in some other environment typically:\n",
        " \n",
        "loaded_model = joblib.load(filename)\n",
        "result = loaded_model.score(X_test, Y_test)\n",
        "print(result)\n",
        "\n",
        "# The X_test and Y_test above ^ are still coming from my colab."
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8116883116883117\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "JmJNuQ8n1Bob",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "15802db1-406d-430f-969e-da7ab458bc80"
      },
      "cell_type": "code",
      "source": [
        "# Load fake data\n",
        "fake_url = \"https://raw.githubusercontent.com/ryanleeallred/fake-data/master/fake-data.csv\"\n",
        "X = pd.read_csv(fake_url)\n",
        "\n",
        "# Y_test = fake['churn']\n",
        "\n",
        "predicted_values = model.predict(X)\n",
        "\n",
        "# print(predicted_values)\n",
        "\n",
        "with_predictions = X\n",
        "with_predictions['churn'] = 0\n",
        "with_predictions['churn'] = predicted_values\n",
        "\n",
        "# View full dataframe with churn predictions\n",
        "with_predictions.head()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>preg</th>\n",
              "      <th>plas</th>\n",
              "      <th>pres</th>\n",
              "      <th>skin</th>\n",
              "      <th>test</th>\n",
              "      <th>mass</th>\n",
              "      <th>pedi</th>\n",
              "      <th>age</th>\n",
              "      <th>churn</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>134</td>\n",
              "      <td>77</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>24.6</td>\n",
              "      <td>1.412</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>168</td>\n",
              "      <td>77</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>42.6</td>\n",
              "      <td>1.141</td>\n",
              "      <td>68</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>190</td>\n",
              "      <td>72</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>29.4</td>\n",
              "      <td>0.419</td>\n",
              "      <td>25</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>132</td>\n",
              "      <td>55</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>23.8</td>\n",
              "      <td>0.398</td>\n",
              "      <td>30</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>166</td>\n",
              "      <td>80</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>33.9</td>\n",
              "      <td>0.224</td>\n",
              "      <td>58</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   preg  plas  pres  skin  test  mass   pedi  age  churn\n",
              "0     1   134    77     0     0  24.6  1.412   29      0\n",
              "1     0   168    77     0     0  42.6  1.141   68      1\n",
              "2     2   190    72     0     0  29.4  0.419   25      1\n",
              "3     4   132    55     0     0  23.8  0.398   30      0\n",
              "4     5   166    80     0     0  33.9  0.224   58      1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "metadata": {
        "id": "PCWNSo0J4vIC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Get the model out of colab-land and onto my machine.\n",
        "from google.colab import files\n",
        "\n",
        "files.download('finalized_model.sav')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QS7d7Z_QCAtV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Running the model on a local Python environment\n",
        "\n",
        "If your local environment has different versioning than your notebook, then you'll need to use something like pipenv in order to control your library/python versions. Luckily all of my versioning is all up to date (had to wipe my machine last month) so we didn't run into any big isssues.\n",
        "\n",
        "## Here is a pretty great pipenv tutorial\n",
        "[http://docs.python-guide.org/en/latest/dev/virtualenvs/](http://docs.python-guide.org/en/latest/dev/virtualenvs/)"
      ]
    },
    {
      "metadata": {
        "id": "Q_4hNwMV5RJG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Use this code in a local python environment to prove to the students that the exported parameterization works.\n",
        "\n",
        "# Load Libraries\n",
        "from sklearn.externals import joblib\n",
        "import pandas as pd\n",
        "\n",
        "# Load fake data\n",
        "fake_url = \"https://raw.githubusercontent.com/ryanleeallred/fake-data/master/fake-data.csv\"\n",
        "X = pd.read_csv(fake_url)\n",
        "\n",
        "# Load previously exported model\n",
        "filename='finalized_model.sav'\n",
        "loaded_model = joblib.load(filename)\n",
        "\n",
        "# predict some values\n",
        "predicted_values = loaded_model.predict(X)\n",
        "\n",
        "# add predictions to dataframe\n",
        "with_predictions = X\n",
        "with_predictions['churn'] = 0\n",
        "with_predictions['churn'] = predicted_values\n",
        "\n",
        "# export dataframe to csv\n",
        "with_predictions.to_csv('fake_predictions.csv', index = False)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}