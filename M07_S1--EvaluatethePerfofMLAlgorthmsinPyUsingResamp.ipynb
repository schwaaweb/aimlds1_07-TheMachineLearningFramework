{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Blog](https://machinelearningmastery.com/evaluate-performance-machine-learning-algorithms-python-using-resampling/)\n",
    "\n",
    "\n",
    "# Evaluate the Performance of Machine Learning Algorithms in Python using Resampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Train and Test Sets.\n",
    "### 2. K-fold Cross Validation\n",
    "### 3. Leave One Out Cross Validation\n",
    "### 4. Repeated Random Test-Train Splits.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Train and Test Sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Positives: fast, good for large data sets\n",
    "\n",
    "Negatives: Can have high variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Accuracy: 75.591'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate using a train and test set\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "df = pd.read_csv('pima-indians-diabetes.data.csv', names=names)\n",
    "array = df.values\n",
    "seed = 7 # This is the random seed\n",
    "\n",
    "X = array[:,0:8]\n",
    "Y = array[:,8]\n",
    "\n",
    "test_size = 0.33 # let the test size be 33% and the training size be 67%\n",
    "X_train, X_test, Y_train, Y_test = model_selection.train_test_split(X, Y, test_size=test_size, random_state=seed)\n",
    "\n",
    "model = LogisticRegression()\n",
    "\n",
    "model.fit(X_train, Y_train)\n",
    "result = model.score(X_test, Y_test)\n",
    "\n",
    "f\"Accuracy: {result*100.0:.3f}\" #  :.3f limits the decimal places to 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. K-Fold Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Positives: Less variance\n",
    "\n",
    "Negative: You must determine appropriate k-parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Accuracy: 76.951 (4.841)'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate using Cross Validation\n",
    "import pandas as pd\n",
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "df = pd.read_csv('pima-indians-diabetes.data.csv', names=names)\n",
    "array = df.values\n",
    "seed = 7 # This is the random seed\n",
    "\n",
    "X = array[:,0:8]\n",
    "Y = array[:,8]\n",
    "\n",
    "num_instances = len(X)\n",
    "\n",
    "kfold = model_selection.KFold(n_splits=10, random_state=seed)\n",
    "\n",
    "model = LogisticRegression()\n",
    "results = model_selection.cross_val_score(model, X, Y, cv=kfold)\n",
    "\n",
    "f\"Accuracy: {results.mean()*100.0:.3f} ({results.std()*100.0:.3f})\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leave One Out Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Positive: Large number of performances that can give a more diverse view of your data\n",
    "    \n",
    "    \n",
    "Negative: More computationally expensive than K-Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Accuracy: 76.823, 42.196'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate using Cross Validation\n",
    "import pandas as pd\n",
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "df = pd.read_csv('pima-indians-diabetes.data.csv', names=names)\n",
    "array = df.values\n",
    "seed = 7 # This is the random seed\n",
    "\n",
    "X = array[:,0:8]\n",
    "Y = array[:,8]\n",
    "\n",
    "num_instances = len(X)\n",
    "\n",
    "loocv = model_selection.LeaveOneOut()\n",
    "\n",
    "model = LogisticRegression()\n",
    "results = model_selection.cross_val_score(model, X, Y, cv=loocv)\n",
    "\n",
    "f\"Accuracy: {results.mean()*100.00:.3f}, {results.std()*100.0:.3f}\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Repeated Random Test-Train Splits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Positives: Speed of train/test split with a reduction in variance\n",
    "\n",
    "Negatives: No garuntee there isn't redundancy in data evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Accuracy: 76.496, 1.698'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evalute suing Shuffle Split Cross Validation\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "df = pd.read_csv('pima-indians-diabetes.data.csv', names=names)\n",
    "array = df.values\n",
    "seed = 7 # This is the random seed\n",
    "\n",
    "X = array[:,0:8]\n",
    "Y = array[:,8]\n",
    "\n",
    "test_size = 0.33 # let the test size be 33% and the training size be 67%\n",
    "\n",
    "num_samples = 10\n",
    "num_instances = len(X)\n",
    "\n",
    "kfold = model_selection.ShuffleSplit(n_splits=10,test_size=test_size, random_state=seed)\n",
    "\n",
    "model = LogisticRegression()\n",
    "results = model_selection.cross_val_score(model, X, Y, cv=kfold)\n",
    "\n",
    "f\"Accuracy: {results.mean()*100.00:.3f}, {results.std()*100.0:.3f}\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What Techniques to Use When\n",
    "\n",
    "* Generally k-fold cross validation is the gold-standard for evaluating the performance of a machine learning algorithm on unseen data with k set to 3, 5, or 10.\n",
    "\n",
    "* Using a train/test split is good for speed when using a slow algorithm and produces performance estimates with lower bias when using large datasets.\n",
    "\n",
    "* Techniques like leave-one-out cross validation and repeated random splits can be useful intermediates when trying to balance variance in the estimated performance, model training speed and dataset size.\n",
    "\n",
    "\n",
    "The best advice is to experiment and find a technique for your problem that is fast and produces reasonable estimates of performance that you can use to make decisions. If in doubt, use 10-fold cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
