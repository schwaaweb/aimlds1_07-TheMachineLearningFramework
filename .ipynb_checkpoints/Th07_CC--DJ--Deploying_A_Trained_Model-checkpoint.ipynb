{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/schwaaweb/aimlds1_07-TheMachineLearningFramework/blob/master/Th07_CC--DJ--Deploying_A_Trained_Model.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "pTf0zGED8g5P",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Deploying a Trained Model\n",
        "\n",
        "Once you have trained and optimized a machine learning model to your satisfaction (or your boss's), it is important to be able to take the trained model and deploy it in a way that will allow it to actually be *used* by stakeholders. This will most likely be on a website or through some other application, but mostly likely you wont want to have everyone coming back to your iPython notebook everytime that they want to make a prediction on new data. \n",
        "\n",
        "When deploying a model it needs to be deployed in an environment that is using the same version of python and the libraries that were use to originally train it, but what is more important is that we preserve the model's parameterization. A model's parameters and hyperparameters are what we've truly been after this whole time. If we could extract a model's parameterization and move those parameters to a similar deployment environment --regardless of whether that is on a website, phone app, or other hardware-- we would be able to make predictions just like usual. Then **if** (a big *if* here) the new data that your model sees in this new enviroment was represented well by the training data, it might even give good predictions.\n",
        "___\n",
        "\n",
        "Today's code challenge is all about getting your model's parameterization out of your iPython notebook in a way that will preserve it and allow the model to be redeployed at a later date."
      ]
    },
    {
      "metadata": {
        "id": "EZW1VcAnwWah",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# LAMBDA SCHOOL\n",
        "# \n",
        "# MACHINE LEARNING\n",
        "#\n",
        "# MIT LICENSE\n",
        "\n",
        "#Code to make your life a little easier\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn import model_selection\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.externals import joblib\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\"\n",
        "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
        "df = pd.read_csv(url, names=names)\n",
        "\n",
        "Y = df['class']\n",
        "X = df.drop(['class'], axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "T7viNtVNDLk5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## The Code Challenge:\n",
        "\n",
        "Your challenge for today, is to:\n",
        "\n",
        "1) Train a logistic regression classifier on the Pima Indians diabetes dataset. Do this using a C value of 20 and a penalty of \"L1\" for your hyperparameters. We'll pretend that we have already done hyperparameter tuning on this model previously for time's sake. \n",
        "\n",
        "2) use sklearn.externals.joblib in order to save a serialized version of your fitted model (which will contain the all-important model parameterization) to your machine\n",
        "\n",
        "3) Upload the saved model from your machine and use it to make predictions on some \"new\" data. I have generated some new (albeit fake) data which lives in this github repository: \n",
        "\n",
        "[https://raw.githubusercontent.com/ryanleeallred/fake-data/master/fake-data.csv](https://raw.githubusercontent.com/ryanleeallred/fake-data/master/fake-data.csv)\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "j0kH3MNNFItd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "##### Your Code Here #####"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}