{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "[Lecture](https://youtu.be/n2M8KEwjwxw)\n",
    "\n",
    "\n",
    "[View in Colaboratory](https://colab.research.google.com/github/schwaaweb/aimlds1_07-TheMachineLearningFramework/blob/master/M07_S0--TC--Lecture_on_Model_Tuning.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9JrCk2HEPwoI"
   },
   "source": [
    "### 1. Compute Linear Regression Model\n",
    "\n",
    "Create a training set and train a Logistic Regression model with it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "5UeD3N5_PwCF",
    "outputId": "29212fba-e96f-41fd-a85e-2b90a703893c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30, 2)\n",
      "(30,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 2,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "#import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = pd.read_csv('https://www.dropbox.com/s/bnwfu81bjpf22hp/logistic_regression.csv?raw=1')\n",
    "# Use train_test_split to create a training set\n",
    "train_x, test_x, train_y, test_y = train_test_split(data[['x1','x2']],data['y'])\n",
    "\n",
    "# Create and train(fit) the model\n",
    "print(train_x.shape)\n",
    "print(train_y.shape)\n",
    "regr = LogisticRegression()\n",
    "regr.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 782
    },
    "colab_type": "code",
    "id": "ZLRACotVtWVw",
    "outputId": "4bd8b304-f50a-49bf-bd35-f95f0f810d67"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     0.0\n",
      "1     0.0\n",
      "2     0.0\n",
      "3     0.0\n",
      "4     0.0\n",
      "5     0.0\n",
      "6     0.0\n",
      "7     0.0\n",
      "8     0.0\n",
      "9     0.0\n",
      "10    0.0\n",
      "11    0.0\n",
      "12    0.0\n",
      "13    0.0\n",
      "14    0.0\n",
      "15    0.0\n",
      "16    0.0\n",
      "17    0.0\n",
      "18    1.0\n",
      "19    0.0\n",
      "20    0.0\n",
      "21    0.0\n",
      "22    0.0\n",
      "23    0.0\n",
      "24    0.0\n",
      "25    0.0\n",
      "26    0.0\n",
      "27    0.0\n",
      "28   -1.0\n",
      "29    0.0\n",
      "30   -1.0\n",
      "31    0.0\n",
      "32    0.0\n",
      "33    0.0\n",
      "34    0.0\n",
      "35    0.0\n",
      "36    0.0\n",
      "37    0.0\n",
      "38    0.0\n",
      "39    0.0\n",
      "Name: y, dtype: float64\n",
      "Accuracy of Overfit model:  0.925\n",
      "Error of Overfit model:  0.075\n",
      "Error of Overfit model:  0.075\n",
      "Error of Overfit model:  0.925\n"
     ]
    }
   ],
   "source": [
    "# FULL DATASET\n",
    "# OVERFIT LOGISTIC REGRESSOIN\n",
    "\n",
    "logr_full = LogisticRegression()\n",
    "logr_full.fit(data[['x1','x2']],data['y'])\n",
    "full_result = logr_full.predict(data[['x1','x2']]) \n",
    "print(full_result - data['y'])\n",
    "print('Accuracy of Overfit model: ', np.sum((full_result - data['y']) == 0)/len(data['y']))\n",
    "print('Error of Overfit model: ', np.sum((full_result - data['y']) != 0)/len(data['y']))\n",
    "\n",
    "# SSE Method:\n",
    "print('Error of Overfit model: ', np.sum((full_result - data['y'])**2)/len(data['y']))\n",
    "print('Error of Overfit model: ', 1.0-(np.sum((full_result - data['y'])**2)/len(data['y'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jSfpHHfJFPc5"
   },
   "source": [
    "### 2. Predict values for $\\hat{y}$ again against the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "x3K306_pFUQc",
    "outputId": "78db3736-b250-4daf-b362-8249b99d50c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error of Overfit model:  0.06666666666666667\n",
      "Error of Overfit model:  0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "# Predict y_hat for the test set created previously\n",
    "\n",
    "y_hat = regr.predict(train_x)\n",
    "\n",
    "results = train_y - y_hat\n",
    "\n",
    "# SSE Method:\n",
    "print('Error of Overfit model: ', np.sum((results)**2)/len(y_hat))\n",
    "print('Error of Overfit model: ', 1.0-(np.sum((results)**2)/len(y_hat)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mbuyZE3UwMC1"
   },
   "source": [
    "### Compare against test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "Fv_8vZvrT44v",
    "outputId": "cbfd0635-632a-4ef3-84f8-c83c4572f910"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 0. 0. 0. 0. 1. 1. 1. 1. 0.]\n",
      "[0.]\n",
      "[0. 1.]\n",
      "Error of test set:  0.1\n",
      "Accuracy of test set:  0.9\n"
     ]
    }
   ],
   "source": [
    "y_hat_test = regr.predict(test_x) # Where's the \"true Y\" to compare with?\n",
    "random_test_one = regr.predict([[0.5,1.5]]) # No \"true Y\" to compare with\n",
    "random_test_two = regr.predict([[0.5,1.5],[6.5,2.1]]) # No \"true Y\" to compare with\n",
    "print(y_hat_test)\n",
    "print(random_test_one)\n",
    "print(random_test_two)\n",
    "                            \n",
    "# Now compare\n",
    "test_result = (y_hat_test - test_y)**2\n",
    "print('Error of test set: ', np.sum(test_result)/len(test_y))\n",
    "print('Accuracy of test set: ', 1.00-np.sum(test_result)/len(test_y))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Lecture on Model Tuning.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
